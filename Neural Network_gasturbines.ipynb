{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "from keras.layers import Dense\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>111.61</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>111.78</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>110.19</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>110.74</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>111.58</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
       "\n",
       "           CO  \n",
       "0      3.1547  \n",
       "1      3.2363  \n",
       "2      3.2012  \n",
       "3      3.1923  \n",
       "4      3.2484  \n",
       "...       ...  \n",
       "15034  4.5186  \n",
       "15035  4.8470  \n",
       "15036  7.9632  \n",
       "15037  6.2494  \n",
       "15038  4.9816  \n",
       "\n",
       "[15039 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset = pd.read_csv(\"C:\\\\Users\\\\Factory\\\\Desktop\\\\Neural Networks\\\\gas_turbines.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset.iloc[:,0:10]\n",
    "Y = dataset.iloc[:,10]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_func(i):\n",
    "    x = (i-i.min())/(i.max()-i.min())\n",
    "    return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = norm_func(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=10, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1504/1504 [==============================] - 4s 1ms/step - loss: -25647.8074 - accuracy: 0.0000e+00\n",
      "Epoch 2/150\n",
      "1504/1504 [==============================] - 1s 853us/step - loss: -699810.4943 - accuracy: 0.0000e+00\n",
      "Epoch 3/150\n",
      "1504/1504 [==============================] - 1s 944us/step - loss: -3020697.5629 - accuracy: 0.0000e+00\n",
      "Epoch 4/150\n",
      "1504/1504 [==============================] - 1s 973us/step - loss: -7414057.4635 - accuracy: 0.0000e+00\n",
      "Epoch 5/150\n",
      "1504/1504 [==============================] - 2s 1ms/step - loss: -14140631.8385 - accuracy: 0.0000e+00\n",
      "Epoch 6/150\n",
      "1504/1504 [==============================] - 2s 1ms/step - loss: -23670244.6857 - accuracy: 0.0000e+00\n",
      "Epoch 7/150\n",
      "1504/1504 [==============================] - 3s 2ms/step - loss: -36185472.6166 - accuracy: 0.0000e+00\n",
      "Epoch 8/150\n",
      "1504/1504 [==============================] - 2s 1ms/step - loss: -51988896.3907 - accuracy: 0.0000e+00\n",
      "Epoch 9/150\n",
      "1504/1504 [==============================] - 2s 1ms/step - loss: -71681670.5143 - accuracy: 0.0000e+00\n",
      "Epoch 10/150\n",
      "1504/1504 [==============================] - 1s 962us/step - loss: -95051776.9568 - accuracy: 0.0000e+00\n",
      "Epoch 11/150\n",
      "1504/1504 [==============================] - 1s 874us/step - loss: -123342905.1056 - accuracy: 0.0000e+00\n",
      "Epoch 12/150\n",
      "1504/1504 [==============================] - 1s 888us/step - loss: -155840242.4877 - accuracy: 0.0000e+00\n",
      "Epoch 13/150\n",
      "1504/1504 [==============================] - 1s 888us/step - loss: -193797735.5163 - accuracy: 0.0000e+00\n",
      "Epoch 14/150\n",
      "1504/1504 [==============================] - 1s 873us/step - loss: -236643583.7023 - accuracy: 0.0000e+00\n",
      "Epoch 15/150\n",
      "1504/1504 [==============================] - 1s 922us/step - loss: -285617273.3130 - accuracy: 0.0000e+00\n",
      "Epoch 16/150\n",
      "1504/1504 [==============================] - 1s 885us/step - loss: -340004754.3495 - accuracy: 0.0000e+00\n",
      "Epoch 17/150\n",
      "1504/1504 [==============================] - 1s 897us/step - loss: -401831652.0399 - accuracy: 0.0000e+00\n",
      "Epoch 18/150\n",
      "1504/1504 [==============================] - 1s 938us/step - loss: -469113949.8525 - accuracy: 0.0000e+00\n",
      "Epoch 19/150\n",
      "1504/1504 [==============================] - 1s 924us/step - loss: -543331766.0917 - accuracy: 0.0000e+00\n",
      "Epoch 20/150\n",
      "1504/1504 [==============================] - 1s 928us/step - loss: -624425665.4884 - accuracy: 0.0000e+00\n",
      "Epoch 21/150\n",
      "1504/1504 [==============================] - 1s 915us/step - loss: -715871639.2611 - accuracy: 0.0000e+00\n",
      "Epoch 22/150\n",
      "1504/1504 [==============================] - 1s 869us/step - loss: -813896713.7807 - accuracy: 0.0000e+00\n",
      "Epoch 23/150\n",
      "1504/1504 [==============================] - 1s 924us/step - loss: -918369965.5442 - accuracy: 0.0000e+00\n",
      "Epoch 24/150\n",
      "1504/1504 [==============================] - 1s 883us/step - loss: -1032363000.4306 - accuracy: 0.0000e+00\n",
      "Epoch 25/150\n",
      "1504/1504 [==============================] - 1s 865us/step - loss: -1156640705.8286 - accuracy: 0.0000e+00\n",
      "Epoch 26/150\n",
      "1504/1504 [==============================] - 1s 979us/step - loss: -1289570413.7143 - accuracy: 0.0000e+00\n",
      "Epoch 27/150\n",
      "1504/1504 [==============================] - 1s 875us/step - loss: -1432130831.0538 - accuracy: 0.0000e+00\n",
      "Epoch 28/150\n",
      "1504/1504 [==============================] - 1s 877us/step - loss: -1580593979.1947 - accuracy: 0.0000e+00\n",
      "Epoch 29/150\n",
      "1504/1504 [==============================] - 1s 890us/step - loss: -1740689197.5867 - accuracy: 0.0000e+00\n",
      "Epoch 30/150\n",
      "1504/1504 [==============================] - 1s 864us/step - loss: -1912618017.3395 - accuracy: 0.0000e+00\n",
      "Epoch 31/150\n",
      "1504/1504 [==============================] - 1s 878us/step - loss: -2101298076.3216 - accuracy: 0.0000e+00\n",
      "Epoch 32/150\n",
      "1504/1504 [==============================] - 1s 864us/step - loss: -2287446194.6047 - accuracy: 0.0000e+00\n",
      "Epoch 33/150\n",
      "1504/1504 [==============================] - 1s 866us/step - loss: -2496394412.3110 - accuracy: 0.0000e+00\n",
      "Epoch 34/150\n",
      "1504/1504 [==============================] - 1s 883us/step - loss: -2713122135.4312 - accuracy: 0.0000e+00\n",
      "Epoch 35/150\n",
      "1504/1504 [==============================] - 1s 886us/step - loss: -2937084380.9595 - accuracy: 0.0000e+00\n",
      "Epoch 36/150\n",
      "1504/1504 [==============================] - 1s 872us/step - loss: -3181868129.2970 - accuracy: 0.0000e+00\n",
      "Epoch 37/150\n",
      "1504/1504 [==============================] - 1s 862us/step - loss: -3434798606.6286 - accuracy: 0.0000e+00\n",
      "Epoch 38/150\n",
      "1504/1504 [==============================] - 1s 878us/step - loss: -3699179180.9914 - accuracy: 0.0000e+00\n",
      "Epoch 39/150\n",
      "1504/1504 [==============================] - 1s 881us/step - loss: -3971111729.1588 - accuracy: 0.0000e+00\n",
      "Epoch 40/150\n",
      "1504/1504 [==============================] - 1s 869us/step - loss: -4272564404.4757 - accuracy: 0.0000e+00\n",
      "Epoch 41/150\n",
      "1504/1504 [==============================] - 1s 862us/step - loss: -4581651450.8970 - accuracy: 0.0000e+00\n",
      "Epoch 42/150\n",
      "1504/1504 [==============================] - 1s 878us/step - loss: -4905699177.2917 - accuracy: 0.0000e+001s -\n",
      "Epoch 43/150\n",
      "1504/1504 [==============================] - 1s 876us/step - loss: -5237702823.7183 - accuracy: 0.0000e+00\n",
      "Epoch 44/150\n",
      "1504/1504 [==============================] - 1s 977us/step - loss: -5577953411.6571 - accuracy: 0.0000e+00\n",
      "Epoch 45/150\n",
      "1504/1504 [==============================] - 2s 1ms/step - loss: -5949233948.4066 - accuracy: 0.0000e+00\n",
      "Epoch 46/150\n",
      "1504/1504 [==============================] - 2s 1ms/step - loss: -6338133020.5767 - accuracy: 0.0000e+00\n",
      "Epoch 47/150\n",
      "1504/1504 [==============================] - 1s 995us/step - loss: -6737252643.8910 - accuracy: 0.0000e+00\n",
      "Epoch 48/150\n",
      "1504/1504 [==============================] - 1s 979us/step - loss: -7151161239.8990 - accuracy: 0.0000e+00\n",
      "Epoch 49/150\n",
      "1504/1504 [==============================] - 2s 1ms/step - loss: -7568514054.1236 - accuracy: 0.0000e+00\n",
      "Epoch 50/150\n",
      "1504/1504 [==============================] - 1s 870us/step - loss: -8005203246.4372 - accuracy: 0.0000e+00\n",
      "Epoch 51/150\n",
      "1504/1504 [==============================] - 1s 874us/step - loss: -8480230755.8485 - accuracy: 0.0000e+00\n",
      "Epoch 52/150\n",
      "1504/1504 [==============================] - 1s 889us/step - loss: -8955340619.6944 - accuracy: 0.0000e+00\n",
      "Epoch 53/150\n",
      "1504/1504 [==============================] - 1s 886us/step - loss: -9432160876.5236 - accuracy: 0.0000e+00\n",
      "Epoch 54/150\n",
      "1504/1504 [==============================] - 1s 933us/step - loss: -9945704961.7010 - accuracy: 0.0000e+00\n",
      "Epoch 55/150\n",
      "1504/1504 [==============================] - 1s 886us/step - loss: -10509711841.0419 - accuracy: 0.0000e+00 1s - loss: -10406406405.22\n",
      "Epoch 56/150\n",
      "1504/1504 [==============================] - 1s 896us/step - loss: -11055218834.2857 - accuracy: 0.0000e+00\n",
      "Epoch 57/150\n",
      "1504/1504 [==============================] - 1s 888us/step - loss: -11623937785.3661 - accuracy: 0.0000e+00\n",
      "Epoch 58/150\n",
      "1504/1504 [==============================] - 1s 897us/step - loss: -12194405030.3575 - accuracy: 0.0000e+00\n",
      "Epoch 59/150\n",
      "1504/1504 [==============================] - 1s 882us/step - loss: -12798178674.8173 - accuracy: 0.0000e+00\n",
      "Epoch 60/150\n",
      "1504/1504 [==============================] - 1s 888us/step - loss: -13436572556.3322 - accuracy: 0.0000e+00\n",
      "Epoch 61/150\n",
      "1504/1504 [==============================] - 1s 887us/step - loss: -14116960396.1621 - accuracy: 0.0000e+00\n",
      "Epoch 62/150\n",
      "1504/1504 [==============================] - 1s 875us/step - loss: -14795670343.6120 - accuracy: 0.0000e+00\n",
      "Epoch 63/150\n",
      "1504/1504 [==============================] - 1s 888us/step - loss: -15427615673.9189 - accuracy: 0.0000e+00\n",
      "Epoch 64/150\n",
      "1504/1504 [==============================] - 1s 886us/step - loss: -16177986393.3023 - accuracy: 0.0000e+00\n",
      "Epoch 65/150\n",
      "1504/1504 [==============================] - 1s 880us/step - loss: -16937034434.9342 - accuracy: 0.0000e+00\n",
      "Epoch 66/150\n",
      "1504/1504 [==============================] - 1s 886us/step - loss: -17620983142.5701 - accuracy: 0.0000e+00\n",
      "Epoch 67/150\n",
      "1504/1504 [==============================] - 1s 878us/step - loss: -18412740416.8080 - accuracy: 0.0000e+00\n",
      "Epoch 68/150\n",
      "1504/1504 [==============================] - 1s 888us/step - loss: -19208604224.9781 - accuracy: 0.0000e+00\n",
      "Epoch 69/150\n",
      "1504/1504 [==============================] - 1s 834us/step - loss: -20048473620.7522 - accuracy: 0.0000e+00\n",
      "Epoch 70/150\n",
      "1504/1504 [==============================] - 1s 823us/step - loss: -20895218533.5495 - accuracy: 0.0000e+00\n",
      "Epoch 71/150\n",
      "1504/1504 [==============================] - 1s 944us/step - loss: -21732798360.5794 - accuracy: 0.0000e+00\n",
      "Epoch 72/150\n",
      "1504/1504 [==============================] - 1s 833us/step - loss: -22661798629.6346 - accuracy: 0.0000e+00\n",
      "Epoch 73/150\n",
      "1504/1504 [==============================] - 1s 825us/step - loss: -23512914415.3302 - accuracy: 0.0000e+00\n",
      "Epoch 74/150\n",
      "1504/1504 [==============================] - 1s 824us/step - loss: -24481365041.6691 - accuracy: 0.0000e+00\n",
      "Epoch 75/150\n",
      "1504/1504 [==============================] - 1s 829us/step - loss: -25462619489.1269 - accuracy: 0.0000e+00\n",
      "Epoch 76/150\n",
      "1504/1504 [==============================] - 1s 827us/step - loss: -26439670781.9588 - accuracy: 0.0000e+00\n",
      "Epoch 77/150\n",
      "1504/1504 [==============================] - 1s 827us/step - loss: -27432532202.0571 - accuracy: 0.0000e+00\n",
      "Epoch 78/150\n",
      "1504/1504 [==============================] - 1s 828us/step - loss: -28421742435.5083 - accuracy: 0.0000e+00\n",
      "Epoch 79/150\n",
      "1504/1504 [==============================] - 1s 821us/step - loss: -29540251452.0452 - accuracy: 0.0000e+00\n",
      "Epoch 80/150\n",
      "1504/1504 [==============================] - 1s 834us/step - loss: -30638949802.6100 - accuracy: 0.0000e+00\n",
      "Epoch 81/150\n",
      "1504/1504 [==============================] - 1s 824us/step - loss: -31763992487.5482 - accuracy: 0.0000e+00\n",
      "Epoch 82/150\n",
      "1504/1504 [==============================] - 1s 823us/step - loss: -32926201050.4080 - accuracy: 0.0000e+00\n",
      "Epoch 83/150\n",
      "1504/1504 [==============================] - 1s 825us/step - loss: -33945897130.0997 - accuracy: 0.0000e+00\n",
      "Epoch 84/150\n",
      "1504/1504 [==============================] - 1s 827us/step - loss: -35199772929.1907 - accuracy: 0.0000e+00\n",
      "Epoch 85/150\n",
      "1504/1504 [==============================] - 1s 823us/step - loss: -36461718874.3229 - accuracy: 0.0000e+00\n",
      "Epoch 86/150\n",
      "1504/1504 [==============================] - 1s 826us/step - loss: -37663059957.1136 - accuracy: 0.0000e+00\n",
      "Epoch 87/150\n",
      "1504/1504 [==============================] - 1s 825us/step - loss: -38968422097.9030 - accuracy: 0.0000e+00\n",
      "Epoch 88/150\n",
      "1504/1504 [==============================] - 1s 833us/step - loss: -40256320456.8877 - accuracy: 0.0000e+00\n",
      "Epoch 89/150\n",
      "1504/1504 [==============================] - 1s 918us/step - loss: -41586362097.2013 - accuracy: 0.0000e+00\n",
      "Epoch 90/150\n",
      "1504/1504 [==============================] - 1s 943us/step - loss: -42883757869.0764 - accuracy: 0.0000e+00\n",
      "Epoch 91/150\n",
      "1504/1504 [==============================] - 1s 946us/step - loss: -44305986657.2970 - accuracy: 0.0000e+00\n",
      "Epoch 92/150\n",
      "1504/1504 [==============================] - 1s 948us/step - loss: -45776448575.2771 - accuracy: 0.0000e+00\n",
      "Epoch 93/150\n",
      "1504/1504 [==============================] - ETA: 0s - loss: -47117097118.3935 - accuracy: 0.0000e+0 - 1s 934us/step - loss: -47125886966.4744 - accuracy: 0.0000e+00\n",
      "Epoch 94/150\n",
      "1504/1504 [==============================] - 1s 946us/step - loss: -48686273943.5588 - accuracy: 0.0000e+00\n",
      "Epoch 95/150\n",
      "1504/1504 [==============================] - 1s 852us/step - loss: -50187264669.5123 - accuracy: 0.0000e+00\n",
      "Epoch 96/150\n",
      "1504/1504 [==============================] - 1s 833us/step - loss: -51712019102.8731 - accuracy: 0.0000e+00\n",
      "Epoch 97/150\n",
      "1504/1504 [==============================] - 1s 842us/step - loss: -53356047567.5216 - accuracy: 0.0000e+00\n",
      "Epoch 98/150\n",
      "1504/1504 [==============================] - 1s 832us/step - loss: -54888961529.5362 - accuracy: 0.0000e+00\n",
      "Epoch 99/150\n",
      "1504/1504 [==============================] - 1s 849us/step - loss: -56411769385.8445 - accuracy: 0.0000e+00\n",
      "Epoch 100/150\n",
      "1504/1504 [==============================] - 1s 857us/step - loss: -58264929891.6784 - accuracy: 0.0000e+00\n",
      "Epoch 101/150\n",
      "1504/1504 [==============================] - 1s 825us/step - loss: -59792962262.6658 - accuracy: 0.0000e+00\n",
      "Epoch 102/150\n",
      "1504/1504 [==============================] - 1s 828us/step - loss: -61331338971.4286 - accuracy: 0.0000e+00\n",
      "Epoch 103/150\n",
      "1504/1504 [==============================] - 1s 835us/step - loss: -63353319440.3296 - accuracy: 0.0000e+00\n",
      "Epoch 104/150\n",
      "1504/1504 [==============================] - 1s 829us/step - loss: -65130146830.2884 - accuracy: 0.0000e+00\n",
      "Epoch 105/150\n",
      "1504/1504 [==============================] - 1s 832us/step - loss: -66997655485.3209 - accuracy: 0.0000e+00\n",
      "Epoch 106/150\n",
      "1504/1504 [==============================] - 1s 823us/step - loss: -68727090032.4359 - accuracy: 0.0000e+00\n",
      "Epoch 107/150\n",
      "1504/1504 [==============================] - 1s 831us/step - loss: -70526911310.4159 - accuracy: 0.0000e+00\n",
      "Epoch 108/150\n",
      "1504/1504 [==============================] - 1s 829us/step - loss: -72673825500.1090 - accuracy: 0.0000e+00\n",
      "Epoch 109/150\n",
      "1504/1504 [==============================] - 1s 829us/step - loss: -74864726301.7674 - accuracy: 0.0000e+00\n",
      "Epoch 110/150\n",
      "1504/1504 [==============================] - 1s 839us/step - loss: -76553666217.0791 - accuracy: 0.0000e+00\n",
      "Epoch 111/150\n",
      "1504/1504 [==============================] - 1s 838us/step - loss: -78599247759.0538 - accuracy: 0.0000e+00\n",
      "Epoch 112/150\n",
      "1504/1504 [==============================] - 1s 823us/step - loss: -80420377542.1661 - accuracy: 0.0000e+00\n",
      "Epoch 113/150\n",
      "1504/1504 [==============================] - 1s 831us/step - loss: -82961075529.9934 - accuracy: 0.0000e+00\n",
      "Epoch 114/150\n",
      "1504/1504 [==============================] - 1s 831us/step - loss: -84881956014.8625 - accuracy: 0.0000e+00\n",
      "Epoch 115/150\n",
      "1504/1504 [==============================] - 1s 852us/step - loss: -87145990485.5601 - accuracy: 0.0000e+00\n",
      "Epoch 116/150\n",
      "1504/1504 [==============================] - 1s 876us/step - loss: -89311836281.1110 - accuracy: 0.0000e+00\n",
      "Epoch 117/150\n",
      "1504/1504 [==============================] - 1s 829us/step - loss: -91470923050.6950 - accuracy: 0.0000e+00\n",
      "Epoch 118/150\n",
      "1504/1504 [==============================] - 2s 1ms/step - loss: -93898075743.5960 - accuracy: 0.0000e+00\n",
      "Epoch 119/150\n",
      "1504/1504 [==============================] - 1s 926us/step - loss: -96258084659.8804 - accuracy: 0.0000e+00\n",
      "Epoch 120/150\n",
      "1504/1504 [==============================] - 1s 826us/step - loss: -98852249099.2266 - accuracy: 0.0000e+00\n",
      "Epoch 121/150\n",
      "1504/1504 [==============================] - 1s 828us/step - loss: -100926118243.1681 - accuracy: 0.0000e+00\n",
      "Epoch 122/150\n",
      "1504/1504 [==============================] - 1s 838us/step - loss: -103335514365.1083 - accuracy: 0.0000e+00\n",
      "Epoch 123/150\n",
      "1504/1504 [==============================] - 1s 838us/step - loss: -105913680002.6366 - accuracy: 0.0000e+00\n",
      "Epoch 124/150\n",
      "1504/1504 [==============================] - 1s 825us/step - loss: -108208078641.1588 - accuracy: 0.0000e+00\n",
      "Epoch 125/150\n",
      "1504/1504 [==============================] - 1s 825us/step - loss: -110880753864.0372 - accuracy: 0.0000e+00\n",
      "Epoch 126/150\n",
      "1504/1504 [==============================] - 1s 864us/step - loss: -113749997944.9409 - accuracy: 0.0000e+00\n",
      "Epoch 127/150\n",
      "1504/1504 [==============================] - 1s 952us/step - loss: -116332901220.1887 - accuracy: 0.0000e+00\n",
      "Epoch 128/150\n",
      "1504/1504 [==============================] - 1s 993us/step - loss: -119006864334.3309 - accuracy: 0.0000e+00\n",
      "Epoch 129/150\n",
      "1504/1504 [==============================] - 1s 840us/step - loss: -121543001413.9110 - accuracy: 0.0000e+00\n",
      "Epoch 130/150\n",
      "1504/1504 [==============================] - 1s 886us/step - loss: -124443679205.8047 - accuracy: 0.0000e+00\n",
      "Epoch 131/150\n",
      "1504/1504 [==============================] - 1s 966us/step - loss: -127091878354.7535 - accuracy: 0.0000e+00\n",
      "Epoch 132/150\n",
      "1504/1504 [==============================] - 1s 880us/step - loss: -129796013562.8970 - accuracy: 0.0000e+00\n",
      "Epoch 133/150\n",
      "1504/1504 [==============================] - 1s 864us/step - loss: -132833960349.6824 - accuracy: 0.0000e+00\n",
      "Epoch 134/150\n",
      "1504/1504 [==============================] - 1s 900us/step - loss: -135785118383.2027 - accuracy: 0.0000e+00\n",
      "Epoch 135/150\n",
      "1504/1504 [==============================] - 1s 944us/step - loss: -138787519162.0891 - accuracy: 0.0000e+00\n",
      "Epoch 136/150\n",
      "1504/1504 [==============================] - 1s 934us/step - loss: -141721622948.4864 - accuracy: 0.0000e+00\n",
      "Epoch 137/150\n",
      "1504/1504 [==============================] - 1s 935us/step - loss: -144969746855.2080 - accuracy: 0.0000e+00\n",
      "Epoch 138/150\n",
      "1504/1504 [==============================] - 1s 933us/step - loss: -147604306541.8844 - accuracy: 0.0000e+00\n",
      "Epoch 139/150\n",
      "1504/1504 [==============================] - 1s 918us/step - loss: -151143633720.6432 - accuracy: 0.0000e+00\n",
      "Epoch 140/150\n",
      "1504/1504 [==============================] - 1s 931us/step - loss: -154348301152.1063 - accuracy: 0.0000e+00\n",
      "Epoch 141/150\n",
      "1504/1504 [==============================] - 1s 827us/step - loss: -157283504952.6432 - accuracy: 0.0000e+00\n",
      "Epoch 142/150\n",
      "1504/1504 [==============================] - 1s 843us/step - loss: -160959376463.6067 - accuracy: 0.0000e+00\n",
      "Epoch 143/150\n",
      "1504/1504 [==============================] - 1s 930us/step - loss: -163898318124.0558 - accuracy: 0.0000e+00\n",
      "Epoch 144/150\n",
      "1504/1504 [==============================] - 1s 882us/step - loss: -167294946672.0957 - accuracy: 0.0000e+00\n",
      "Epoch 145/150\n",
      "1504/1504 [==============================] - 2s 1ms/step - loss: -170875913933.8206 - accuracy: 0.0000e+00\n",
      "Epoch 146/150\n",
      "1504/1504 [==============================] - 1s 811us/step - loss: -174395996792.7708 - accuracy: 0.0000e+00\n",
      "Epoch 147/150\n",
      "1504/1504 [==============================] - 1s 890us/step - loss: -177651175802.3017 - accuracy: 0.0000e+00\n",
      "Epoch 148/150\n",
      "1504/1504 [==============================] - 1s 906us/step - loss: -181290029630.2565 - accuracy: 0.0000e+00\n",
      "Epoch 149/150\n",
      "1504/1504 [==============================] - 1s 975us/step - loss: -184762593968.5634 - accuracy: 0.0000e+00\n",
      "Epoch 150/150\n",
      "1504/1504 [==============================] - 1s 973us/step - loss: -188785684798.4266 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2454832c280>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_norm, Y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 0s 727us/step - loss: -191375081472.0000 - accuracy: 0.0000e+00\n",
      "Accuracy:  \n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(X, Y)\n",
    "print('Accuracy:  ' %(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
